import os
import sys

cwd = os.getcwd()
sys.path.append( cwd )
new_path = [ os.path.join( cwd, "scripts" ),
             os.path.join( cwd, "lib" ),
             os.path.join( cwd, 'test' ),
             os.path.join( cwd, 'scripts', 'api' ) ]
new_path.extend( sys.path )
sys.path = new_path

from galaxy import eggs
eggs.require( 'mercurial' )
eggs.require( "nose" )

import logging
import install_and_test_tool_shed_repositories.base.test_db_util as test_db_util
import install_and_test_tool_shed_repositories.functional.test_install_repositories as test_install_repositories
import nose
import platform
import time
import tool_shed.repository_types.util as rt_util
import tool_shed.util.shed_util_common as suc
import urllib

from datetime import datetime
from datetime import timedelta

from common import update

from galaxy.util import asbool
from galaxy.util import listify
from galaxy.util import unicodify
from galaxy.util.json import from_json_string
import galaxy.webapps.tool_shed.model.mapping

from nose.plugins import Plugin
from tool_shed.util import tool_dependency_util

from tool_shed.util.xml_util import parse_xml

from mercurial import hg
from mercurial import ui

log = logging.getLogger(__name__)

# Set up a job_conf.xml that explicitly limits jobs to 10 minutes.
job_conf_xml = '''<?xml version="1.0"?>
<!-- A test job config that explicitly configures job running the way it is configured by default (if there is no explicit config). -->
<job_conf>
    <plugins>
        <plugin id="local" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner" workers="4"/>
    </plugins>
    <handlers>
        <handler id="main"/>
    </handlers>
    <destinations>
        <destination id="local" runner="local"/>
    </destinations>
    <limits>
        <limit type="walltime">00:10:00</limit>
    </limits>
</job_conf>
'''

# Create a blank shed_tool_conf.xml to define the installed repositories.
shed_tool_conf_xml_template = '''<?xml version="1.0"?>
<toolbox tool_path="${shed_tool_path}">
</toolbox>
'''

# Since we will be running functional tests we'll need the upload tool, but the rest can be omitted.
tool_conf_xml = '''<?xml version="1.0"?>
<toolbox>
    <section name="Get Data" id="getext">
        <tool file="data_source/upload.xml"/>
    </section>
</toolbox>
'''

# Set up an empty shed_tool_data_table_conf.xml.
tool_data_table_conf_xml_template = '''<?xml version="1.0"?>
<tables>
</tables>
'''

# Optionally set the environment variable GALAXY_INSTALL_TEST_TOOL_SHEDS_CONF to the location of a
# tool shed's configuration file that includes the tool shed from which repositories will be installed.
tool_sheds_conf_xml = '''<?xml version="1.0"?>
<tool_sheds>
    <tool_shed name="Galaxy main tool shed" url="http://toolshed.g2.bx.psu.edu/"/>
    <tool_shed name="Galaxy test tool shed" url="http://testtoolshed.g2.bx.psu.edu/"/>
</tool_sheds>
'''

# Should this serve static resources (scripts, images, styles, etc.)?
STATIC_ENABLED = True

# If we have a tool_data_table_conf.test.xml, set it up to be loaded when the UniverseApplication is started.
# This allows one to specify a set of tool data that is used exclusively for testing, and not loaded into any
# Galaxy instance. By default, this will be in the test-data-repo/location directory generated by buildbot_setup.sh.
if os.path.exists( 'tool_data_table_conf.test.xml' ):
    additional_tool_data_tables = 'tool_data_table_conf.test.xml'
    additional_tool_data_path = os.environ.get( 'GALAXY_INSTALL_TEST_EXTRA_TOOL_DATA_PATH',
                                                os.path.join( 'test-data-repo', 'location' ) )
else:
    additional_tool_data_tables = None
    additional_tool_data_path = None

# Set up default tool data tables.
if os.path.exists( 'tool_data_table_conf.xml' ):
    tool_data_table_conf = 'tool_data_table_conf.xml'
elif os.path.exists( 'tool_data_table_conf.xml.sample' ):
    tool_data_table_conf = 'tool_data_table_conf.xml.sample'
else:
    tool_data_table_conf = None

# The GALAXY_INSTALL_TEST_TOOL_SHED_URL and GALAXY_INSTALL_TEST_TOOL_SHED_API_KEY environment variables must be
# set for this script to work correctly.  If the value of GALAXY_INSTALL_TEST_TOOL_SHED_URL does not refer to one
# of the defaults, the GALAXY_INSTALL_TEST_TOOL_SHEDS_CONF must refer to a tool shed configuration file that contains
# a definition for that tool shed.
galaxy_tool_shed_url = os.environ.get( 'GALAXY_INSTALL_TEST_TOOL_SHED_URL', None )
tool_shed_api_key = os.environ.get( 'GALAXY_INSTALL_TEST_TOOL_SHED_API_KEY', None )

if 'GALAXY_INSTALL_TEST_SECRET' not in os.environ:
    galaxy_encode_secret = 'changethisinproductiontoo'
    os.environ[ 'GALAXY_INSTALL_TEST_SECRET' ] = galaxy_encode_secret
else:
    galaxy_encode_secret = os.environ[ 'GALAXY_INSTALL_TEST_SECRET' ]

default_galaxy_test_port_min = 10000
default_galaxy_test_port_max = 10999
default_galaxy_test_host = '127.0.0.1'
# The following should be an actual value (not None).  If developers manually specify their
# tests to use the API it will not work unless a master API key is specified.
default_galaxy_master_api_key = 123456

testing_single_repository_dict = {}
if 'repository_name' in os.environ and 'repository_owner' in os.environ:
    testing_single_repository_dict[ 'name' ] = str( os.environ[ 'repository_name' ] )
    testing_single_repository_dict[ 'owner' ] = str( os.environ[ 'repository_owner' ] )
    if 'repository_revision' in os.environ:
        testing_single_repository_dict[ 'changeset_revision' ] = str( os.environ[ 'repository_revision' ] )
    else:
        testing_single_repository_dict[ 'changeset_revision' ] = None

# Test frameworks that use this utility module.
REPOSITORIES_WITH_TOOLS = 'repositories_with_tools'
TOOL_DEPENDENCY_DEFINITIONS = 'tool_dependency_definitions'

class ReportResults( Plugin ):
    '''Simple Nose plugin to record the IDs of all tests run, regardless of success.'''
    name = "reportresults"
    passed = {}

    def options( self, parser, env=os.environ ):
        super( ReportResults, self ).options( parser, env=env )

    def configure(self, options, conf):
        super( ReportResults, self ).configure( options, conf )
        if not self.enabled:
            return

    def addSuccess( self, test ):
        '''Only record test IDs that correspond to tool functional tests.'''
        if 'TestForTool' in test.id():
            test_id = test.id()
            # Rearrange the test ID to match the format that is produced in test_results.failures
            test_id_parts = test_id.split( '.' )
            fixed_test_id = '%s (%s)' % ( test_id_parts[ -1 ], '.'.join( test_id_parts[ :-1 ] ) )
            test_parts = fixed_test_id.split( '/' )
            owner = test_parts[ -4 ]
            name = test_parts[ -3 ]
            test_identifier = '%s/%s' % ( owner, name )
            if test_identifier not in self.passed:
                self.passed[ test_identifier ] = []
            self.passed[ test_identifier ].append( fixed_test_id )

    def getTestStatus( self, test_identifier ):
        if test_identifier in self.passed:
            passed_tests = self.passed[ test_identifier ]
            del self.passed[ test_identifier ]
            return passed_tests
        return []


class RepositoryMetadataApplication( object ):
    """Application that enables updating repository_metadata table records in the Tool Shed."""

    def __init__( self, config ):
        self.config = config
        if self.config.database_connection is False:
            self.config.database_connection = "sqlite:///%s?isolation_level=IMMEDIATE" % str( config.database )
        log.debug( 'Using database connection: %s' % str( self.config.database_connection ) )
        # Setup the database engine and ORM
        self.model = galaxy.webapps.tool_shed.model.mapping.init( self.config.file_path,
                                                                  self.config.database_connection,
                                                                  engine_options={},
                                                                  create_tables=False )
        self.hgweb_config_manager = self.model.hgweb_config_manager
        self.hgweb_config_manager.hgweb_config_dir = self.config.hgweb_config_dir
        log.debug( 'Using hgweb.config file: %s' % str( self.hgweb_config_manager.hgweb_config ) )

    @property
    def sa_session( self ):
        """Returns a SQLAlchemy session."""
        return self.model.context.current

    def shutdown( self ):
        pass

def clean_tool_shed_url( base_url ):
    """Eliminate the protocol from the received base_url and return the possibly altered url."""
    # The tool_shed value stored in the tool_shed_repository record does not include the protocol, but does
    # include the port if one exists.
    if base_url:
        if base_url.find( '://' ) > -1:
            try:
                protocol, base = base_url.split( '://' )
            except ValueError, e:
                # The received base_url must be an invalid url.
                log.debug( "Returning unchanged invalid base_url from clean_tool_shed_url: %s" % str( base_url ) )
                return base_url
            return base.rstrip( '/' )
        return base_url.rstrip( '/' )
    log.debug( "Returning base_url from clean_tool_shed_url: %s" % str( base_url ) )
    return base_url

def display_repositories_by_owner( repository_dicts ):
    # Group summary display by repository owner.
    repository_dicts_by_owner = {}
    for repository_dict in repository_dicts:
        name = str( repository_dict[ 'name' ] )
        owner = str( repository_dict[ 'owner' ] )
        changeset_revision = str( repository_dict[ 'changeset_revision' ] )
        if owner in repository_dicts_by_owner:
            repository_dicts_by_owner[ owner ].append( repository_dict )
        else:
            repository_dicts_by_owner[ owner ] = [ repository_dict ]
    # Display grouped summary.
    for owner, grouped_repository_dicts in repository_dicts_by_owner.items():
        print "# "
        for repository_dict in grouped_repository_dicts:
            name = str( repository_dict[ 'name' ] )
            owner = str( repository_dict[ 'owner' ] )
            changeset_revision = str( repository_dict[ 'changeset_revision' ] )
            print "# Revision %s of repository %s owned by %s" % ( changeset_revision, name, owner )

def display_tool_dependencies_by_name( tool_dependency_dicts ):
    # Group summary display by repository owner.
    tool_dependency_dicts_by_name = {}
    for tool_dependency_dict in tool_dependency_dicts:
        name = str( tool_dependency_dict[ 'name' ] )
        type = str( tool_dependency_dict[ 'type' ] )
        version = str( tool_dependency_dict[ 'version' ] )
        if name in tool_dependency_dicts_by_name:
            tool_dependency_dicts_by_name[ name ].append( tool_dependency_dict )
        else:
            tool_dependency_dicts_by_name[ name ] = [ tool_dependency_dict ]
    # Display grouped summary.
    for name, grouped_tool_dependency_dicts in tool_dependency_dicts_by_name.items():
        print "# "
        for tool_dependency_dict in grouped_tool_dependency_dicts:
            type = str( tool_dependency_dict[ 'type' ] )
            name = str( tool_dependency_dict[ 'name' ] )
            version = str( tool_dependency_dict[ 'version' ] )
            print "# %s %s version %s" % ( type, name, version )

def get_api_url( base, parts=[], params=None ):
    if 'api' in parts and parts.index( 'api' ) != 0:
        parts.pop( parts.index( 'api' ) )
        parts.insert( 0, 'api' )
    elif 'api' not in parts:
        parts.insert( 0, 'api' )
    url = suc.url_join( base, *parts )
    if params is not None:
        query_string = urllib.urlencode( params )
        url += '?%s' % query_string
    return url

def get_database_version( app ):
    '''
    This method returns the value of the version column from the migrate_version table, using the provided app's SQLAlchemy session to determine
    which table to get that from. This way, it's provided with an instance of a Galaxy UniverseApplication, it will return the Galaxy instance's
    database migration version. If a tool shed UniverseApplication is provided, it returns the tool shed's database migration version.
    '''
    sa_session = app.model.context.current
    result = sa_session.execute( 'SELECT version FROM migrate_version LIMIT 1' )
    # This query will return the following structure:
    # row = [ column 0, column 1, ..., column n ]
    # rows = [ row 0, row 1, ..., row n ]
    # The first column in the first row is the version number we want.
    for row in result:
        version = row[ 0 ]
        break
    return version

def get_latest_downloadable_changeset_revision( url, name, owner ):
    error_message = ''
    parts = [ 'api', 'repositories', 'get_ordered_installable_revisions' ]
    params = dict( name=name, owner=owner )
    api_url = get_api_url( base=url, parts=parts, params=params )
    changeset_revisions, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    if changeset_revisions:
        return changeset_revisions[ -1 ], error_message
    else:
        return suc.INITIAL_CHANGELOG_HASH, error_message

def get_missing_repository_dependencies( repository ):
    """
    Return the entire list of missing repository dependencies for the received repository.  The entire
    dependency tree will be inspected.
    """
    log.debug( 'Checking revision %s of repository %s owned by %s for missing repository dependencies.' % \
        ( str( repository.changeset_revision ), str( repository.name ), str( repository.owner ) ) )
    missing_repository_dependencies = repository.missing_repository_dependencies
    for missing_required_repository in missing_repository_dependencies:
        log.debug( 'Revision %s of required repository %s owned by %s has status %s.' % \
            ( str( missing_required_repository.changeset_revision ),
              str( missing_required_repository.name ),
              str( missing_required_repository.owner ),
              str( missing_required_repository.status ) ) )
    for repository_dependency in repository.repository_dependencies:
        if repository_dependency.missing_repository_dependencies:
            missing_repository_dependencies.extend( get_missing_repository_dependencies( repository_dependency ) )
    return missing_repository_dependencies

def get_missing_tool_dependencies( repository ):
    """
    Return the entire list of missing tool dependencies for the received repository.  The entire
    dependency tree will be inspected.
    """
    log.debug( 'Checking revision %s of repository %s owned by %s for missing tool dependencies.' % \
        ( str( repository.changeset_revision ), str( repository.name ), str( repository.owner ) ) )
    missing_tool_dependencies = repository.missing_tool_dependencies
    for missing_tool_dependency in missing_tool_dependencies:
        log.debug( 'Tool dependency %s version %s has status %s.' % \
            ( str( missing_tool_dependency.name ), str( missing_tool_dependency.version ), str( missing_tool_dependency.status ) ) )
    for repository_dependency in repository.repository_dependencies:
        if repository_dependency.includes_tool_dependencies:
            missing_tool_dependencies.extend( get_missing_tool_dependencies( repository_dependency ) )
    return missing_tool_dependencies

def get_repositories_to_install( tool_shed_url, test_framework ):
    """
    Get a list of repository info dicts to install. This method expects a json list of dicts with the following structure:
    [{ "changeset_revision": <revision>,
       "encoded_repository_id": <encoded repository id from the tool shed>,
       "name": <name>,
       "owner": <owner>,
       "tool_shed_url": <url> }]
    """
    error_message = ''
    latest_revision_only = '-check_all_revisions' not in sys.argv
    if latest_revision_only:
        log.debug( 'Testing is restricted to the latest downloadable revision in this test run.' )
    repository_dicts = []
    parts = [ 'repository_revisions' ]
    # We'll filter out deprecated repositories from testing since testing them is necessary only if reproducibility
    # is guaranteed and we currently do not guarantee reproducibility.
    if test_framework == REPOSITORIES_WITH_TOOLS:
        params = dict( do_not_test='false',
                       downloadable='true',
                       includes_tools='true',
                       malicious='false',
                       missing_test_components='false',
                       skip_tool_test='false' )
    elif test_framework == TOOL_DEPENDENCY_DEFINITIONS:
        params = dict( do_not_test='false',
                       downloadable='true',
                       malicious='false',
                       skip_tool_test='false' )
    api_url = get_api_url( base=tool_shed_url, parts=parts, params=params )
    baseline_repository_dicts, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    for baseline_repository_dict in baseline_repository_dicts:
        # We need to get some details from the tool shed API, such as repository name and owner, to pass on to the
        # module that will generate the install methods.
        repository_dict, error_message = get_repository_dict( galaxy_tool_shed_url, baseline_repository_dict )
        if error_message:
            log.debug( 'Error getting additional details from the API: %s' % str(  error_message ) )
        else:
            # Don't test deprecated repositories since testing them is necessary only if reproducibility is guaranteed
            # and we are not currently guaranteeing reproducibility.
            deprecated = asbool( repository_dict.get( 'deprecated', False ) )
            if not deprecated:
                # Don't test empty repositories.
                changeset_revision = baseline_repository_dict[ 'changeset_revision' ]
                if changeset_revision != suc.INITIAL_CHANGELOG_HASH:
                    # If testing repositories of type tool_dependency_definition, filter accordingly.
                    if test_framework == TOOL_DEPENDENCY_DEFINITIONS and repository_dict[ 'type' ] != rt_util.TOOL_DEPENDENCY_DEFINITION:
                        continue
                    # Merge the dictionary returned from /api/repository_revisions with the detailed repository_dict and
                    # append it to the list of repository_dicts to install and test.
                    if latest_revision_only:
                        latest_revision = repository_dict[ 'latest_revision' ]
                        if changeset_revision == latest_revision:
                            repository_dicts.append( dict( repository_dict.items() + baseline_repository_dict.items() ) )
                    else:
                        repository_dicts.append( dict( repository_dict.items() + baseline_repository_dict.items() ) )
    if testing_single_repository_dict:
        tsr_name = testing_single_repository_dict[ 'name' ]
        tsr_owner = testing_single_repository_dict[ 'owner' ]
        tsr_changeset_revision = testing_single_repository_dict[ 'changeset_revision' ]
        log.debug( 'Testing single repository with name %s and owner %s.' % ( str( tsr_name ), str( tsr_owner ) ) )
        for repository_to_install in repository_dicts:
            rti_name = repository_to_install[ 'name' ]
            rti_owner = repository_to_install[ 'owner' ]
            rti_changeset_revision = repository_to_install[ 'changeset_revision' ]
            if rti_name == tsr_name and rti_owner == tsr_owner:
                if tsr_changeset_revision is None:
                    return [ repository_to_install ], error_message
                else:
                    if tsr_changeset_revision == rti_changeset_revision:
                        return repository_dicts, error_message
        return repository_dicts, error_message
    # Get a list of repositories to test from the tool shed specified in the GALAXY_INSTALL_TEST_TOOL_SHED_URL
    # environment variable.
    log.debug( "The Tool Shed's API url...\n%s" % str( api_url ) )
    log.debug( "...retrieved %d repository revisions for installation and possible testing." % len( repository_dicts ) )
    log.debug( "Repository revisions for testing:" )
    for repository_dict in repository_dicts:
        name = str( repository_dict.get( 'name', None ) )
        owner = str( repository_dict.get( 'owner', None ) )
        changeset_revision = str( repository_dict.get( 'changeset_revision', None ) )
        log.debug( "Revision %s of repository %s owned by %s" % ( changeset_revision, name, owner ) )
    return repository_dicts, error_message

def get_repository( name, owner, changeset_revision ):
    """Return a repository record associated with the received name, owner, changeset_revision if one exists."""
    repository = None
    try:
        repository = test_db_util.get_installed_repository_by_name_owner_changeset_revision( name, owner, changeset_revision )
    except:
        # The repository may not have been installed in a previous test.
        pass
    return repository

def get_repository_current_revision( repo_path ):
    """This method uses the python mercurial API to get the current working directory's mercurial changeset hash."""
    # Initialize a mercurial repo object from the provided path.
    repo = hg.repository( ui.ui(), repo_path )
    # Get the working directory's change context.
    ctx = repo[ None ]
    # Extract the changeset hash of the first parent of that change context (the most recent changeset to which the
    # working directory was updated).
    changectx = ctx.parents()[ 0 ]
    # Also get the numeric revision, so we can return the customary id:hash changeset identifiers.
    ctx_rev = changectx.rev()
    hg_id = '%d:%s' % ( ctx_rev, str( changectx ) )
    return hg_id

def get_repository_dependencies_for_changeset_revision( tool_shed_url, encoded_repository_metadata_id ):
    """
    Return the list of dictionaries that define all repository dependencies of the repository_metadata
    record associated with the received encoded_repository_metadata_id via the Tool Shed API.
    """
    error_message = ''
    parts = [ 'api', 'repository_revisions', encoded_repository_metadata_id, 'repository_dependencies' ]
    api_url = get_api_url( base=tool_shed_url, parts=parts )
    repository_dependency_dicts, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    return repository_dependency_dicts, error_message

def get_repository_dict( url, repository_dict ):
    error_message = ''
    if not isinstance( repository_dict, dict ):
        error_message = 'Invalid repository_dict received: %s' % str( repository_dict )
        return None, error_message
    repository_id = repository_dict.get( 'repository_id', None )
    if repository_id is None:
        error_message = 'Invalid repository_dict does not contain a repository_id entry: %s' % str( repository_dict )
        return None, error_message
    parts = [ 'api', 'repositories', repository_id ]
    api_url = get_api_url( base=url, parts=parts )
    extended_dict, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    name = str( extended_dict[ 'name' ] )
    owner = str( extended_dict[ 'owner' ] )
    latest_changeset_revision, error_message = get_latest_downloadable_changeset_revision( url, name, owner )
    if error_message:
        return None, error_message
    extended_dict[ 'latest_revision' ] = str( latest_changeset_revision )
    return extended_dict, error_message

def get_repository_dependencies_dicts( url, encoded_repository_metadata_id ):
    """
    Return a list if dictionaries that define the repository dependencies of the repository defined by the
    received repository_dict.
    """
    error_message = ''
    parts = [ 'api', 'repository_revisions', encoded_repository_metadata_id, 'repository_dependencies' ]
    api_url = get_api_url( base=url, parts=parts )
    repository_dependencies_dicts, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    return repository_dependencies_dicts, error_message

def get_repository_tuple_from_elem( elem ):
    attributes = elem.attrib
    name = attributes.get( 'name', None )
    owner = attributes.get( 'owner', None )
    changeset_revision = attributes.get( 'changeset_revision', None )
    return ( name, owner, changeset_revision )

def get_static_settings():
    """
    Return a dictionary of the settings necessary for a Galaxy application to be wrapped in the static
    middleware.  This mainly consists of the file system locations of url-mapped static resources.
    """
    cwd = os.getcwd()
    static_dir = os.path.join( cwd, 'static' )
    #TODO: these should be copied from universe_wsgi.ini
    #TODO: static_enabled needed here?
    return dict( static_enabled = True,
                 static_cache_time = 360,
                 static_dir = static_dir,
                 static_images_dir = os.path.join( static_dir, 'images', '' ),
                 static_favicon_dir = os.path.join( static_dir, 'favicon.ico' ),
                 static_scripts_dir = os.path.join( static_dir, 'scripts', '' ),
                 static_style_dir = os.path.join( static_dir, 'june_2007_style', 'blue' ),
                 static_robots_txt = os.path.join( static_dir, 'robots.txt' ) )

def get_time_last_tested( tool_shed_url, encoded_repository_metadata_id ):
    """
    Return the datetime value stored in the Tool Shed's repository_metadata.time_last_tested column
    via the Tool Shed API.
    """
    error_message = ''
    parts = [ 'api', 'repository_revisions', encoded_repository_metadata_id ]
    api_url = get_api_url( base=tool_shed_url, parts=parts )
    repository_metadata_dict, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    if isinstance( repository_metadata_dict, dict ):
        # The tool_test_results used to be stored as a single dictionary rather than a list, but we currently
        # return a list.
        time_last_tested = repository_metadata_dict.get( 'time_last_tested', None )
        return time_last_tested, error_message
    else:
        error_message = 'The url %s returned the invalid repository_metadata_dict %s' % ( str( api_url ), str( repository_metadata_dict ) )
        return None, error_message

def get_tool_test_results_dict( tool_test_results_dicts ):
    if tool_test_results_dicts:
        # Inspect the tool_test_results_dict for the last test run to make sure it contains only a test_environment
        # entry.  If it contains more entries, then the script ~/tool_shed/api/check_repositories_for_functional_tests.py
        # was not executed in preparation for this script's execution, so we'll just create an empty dictionary.
        tool_test_results_dict = tool_test_results_dicts[ 0 ]
        if len( tool_test_results_dict ) <= 1:
            # We can re-use the mostly empty tool_test_results_dict for this run because it is either empty or it contains only
            # a test_environment entry.  If we use it we need to temporarily eliminate it from the list of tool_test_results_dicts
            # since it will be re-inserted later.
            tool_test_results_dict = tool_test_results_dicts.pop( 0 )
        elif len( tool_test_results_dict ) == 2 and \
            'test_environment' in tool_test_results_dict and 'missing_test_components' in tool_test_results_dict:
            # We can re-use tool_test_results_dict if its only entries are "test_environment" and "missing_test_components".
            # In this case, some tools are missing tests components while others are not.
            tool_test_results_dict = tool_test_results_dicts.pop( 0 )
        else:
            # The latest tool_test_results_dict has been populated with the results of a test run, so it cannot be used.
            tool_test_results_dict = {}
    else:
        # Create a new dictionary for this test test run, 
        tool_test_results_dict = {}
    return tool_test_results_dict

def get_tool_test_results_dicts( tool_shed_url, encoded_repository_metadata_id ):
    """
    Return the list of dictionaries contained in the Tool Shed's repository_metadata.tool_test_results
    column via the Tool Shed API.
    """
    error_message = ''
    parts = [ 'api', 'repository_revisions', encoded_repository_metadata_id ]
    api_url = get_api_url( base=tool_shed_url, parts=parts )
    repository_metadata_dict, error_message = json_from_url( api_url )
    if error_message:
        return None, error_message
    if isinstance( repository_metadata_dict, dict ):
        # The tool_test_results used to be stored as a single dictionary rather than a list, but we currently
        # return a list.
        tool_test_results = listify( repository_metadata_dict.get( 'tool_test_results', [] ) )
        return tool_test_results, error_message
    else:
        error_message = 'The url %s returned the invalid repository_metadata_dict %s' % ( str( api_url ), str( repository_metadata_dict ) )
        return None, error_message

def get_webapp_global_conf():
    """Return the global_conf dictionary sent as the first argument to app_factory."""
    global_conf = {}
    if STATIC_ENABLED:
        global_conf.update( get_static_settings() )
    return global_conf

def initialize_install_and_test_statistics_dict( test_framework ):
    # Initialize a dictionary for the summary that will be printed to stdout.
    install_and_test_statistics_dict = {}
    install_and_test_statistics_dict[ 'total_repositories_processed' ] = 0
    install_and_test_statistics_dict[ 'successful_repository_installations' ] = []
    install_and_test_statistics_dict[ 'successful_tool_dependency_installations' ] = []
    install_and_test_statistics_dict[ 'repositories_with_installation_error' ] = []
    install_and_test_statistics_dict[ 'tool_dependencies_with_installation_error' ] = []
    if test_framework == REPOSITORIES_WITH_TOOLS:
        install_and_test_statistics_dict[ 'all_tests_passed' ] = []
        install_and_test_statistics_dict[ 'at_least_one_test_failed' ] = []
    return install_and_test_statistics_dict

def initialize_tool_tests_results_dict( app, tool_test_results_dict ):
    test_environment_dict = tool_test_results_dict.get( 'test_environment', {} )
    if len( test_environment_dict ) == 0:
        # Set information about the tool shed to nothing since we cannot currently determine it from here.
        # We could eventually add an API method...
        test_environment_dict = dict( tool_shed_database_version='',
                                      tool_shed_mercurial_version='',
                                      tool_shed_revision='' )
    # Add the current time as the approximate time that this test run occurs.  A similar value will also be
    # set to the repository_metadata.time_last_tested column, but we also store it here because the Tool Shed
    # may be configured to store multiple test run results, so each must be associated with a time stamp.
    now = time.strftime( "%Y-%m-%d %H:%M:%S" )
    # Add information about the current platform.
    test_environment_dict[ 'time_tested' ] = now
    test_environment_dict[ 'python_version' ] = platform.python_version()
    test_environment_dict[ 'architecture' ] = platform.machine()
    operating_system, hostname, operating_system_version, uname, arch, processor = platform.uname()
    test_environment_dict[ 'system' ] = '%s %s' % ( operating_system, operating_system_version )
    # Add information about the current Galaxy environment.
    test_environment_dict[ 'galaxy_database_version' ] = get_database_version( app )
    test_environment_dict[ 'galaxy_revision' ] = get_repository_current_revision( os.getcwd() )
    # Initialize and populate the tool_test_results_dict.
    tool_test_results_dict[ 'test_environment' ] = test_environment_dict
    tool_test_results_dict[ 'passed_tests' ] = []
    tool_test_results_dict[ 'failed_tests' ] = []
    tool_test_results_dict[ 'installation_errors' ] = dict( current_repository=[],
                                                            repository_dependencies=[],
                                                            tool_dependencies=[] )
    tool_test_results_dict[ 'successful_installations' ] = dict( current_repository=[],
                                                                 repository_dependencies=[],
                                                                 tool_dependencies=[] )
    return tool_test_results_dict

def install_repository( app, repository_dict ):
    """Install a repository defined by the received repository_dict from the tool shed into Galaxy."""
    name = str( repository_dict[ 'name' ] )
    owner = str( repository_dict[ 'owner' ] )
    changeset_revision = str( repository_dict[ 'changeset_revision' ] )
    error_message = ''
    repository = None
    log.debug( "Installing revision %s of repository %s owned by %s." % ( changeset_revision, name, owner ) )
    # Use the repository information dictionary to generate an install method that will install the repository into the
    # embedded Galaxy application, with tool dependencies and repository dependencies, if any.
    test_install_repositories.generate_install_method( repository_dict )
    # Configure nose to run the install method as a test.
    test_config = nose.config.Config( env=os.environ, plugins=nose.plugins.manager.DefaultPluginManager() )
    test_config.configure( sys.argv )
    # Run the configured install method as a test. This method uses the embedded Galaxy application's web interface to
    # install the specified repository with tool and repository dependencies also selected for installation.
    result, _ = run_tests( test_config )
    # Get the repository record now that the tests that install it have completed.
    repository = get_repository( name, owner, changeset_revision )
    if repository is None:
        error_message = 'Error getting revision %s of repository %s owned by %s: %s' % ( changeset_revision, name, owner, str( e ) )
        log.exception( error_message )
    return repository, error_message

def is_excluded( exclude_list_dicts, name, owner, changeset_revision, encoded_repository_metadata_id ):
    """
    Return True if the repository defined by the received name, owner, changeset_revision should
    be excluded from testing for any reason.
    """
    for exclude_dict in exclude_list_dicts:
        reason = exclude_dict[ 'reason' ]
        exclude_repositories = exclude_dict[ 'repositories' ]
        # 'repositories':
        #    [( name, owner, changeset_revision if changeset_revision else None ),
        #     ( name, owner, changeset_revision if changeset_revision else None )]
        if ( name, owner, changeset_revision ) in exclude_repositories or ( name, owner, None ) in exclude_repositories:
            log.debug( 'Revision %s of repository %s owned by %s is excluded from testing because:\n%s' % \
                ( str( changeset_revision ), str( name ), str( owner ), str( reason ) ) )
            return True, reason
        # Skip this repository if it has a repository dependency that is in the exclude list.
        repository_dependency_dicts, error_message = \
            get_repository_dependencies_for_changeset_revision( galaxy_tool_shed_url, encoded_repository_metadata_id )
        if error_message:
            log.debug( 'Error getting repository dependencies for revision %s of repository %s owned by %s:' % \
                ( changeset_revision, name, owner ) )
            log.debug( error_message )
        else:
            for repository_dependency_dict in repository_dependency_dicts:
                rd_name = repository_dependency_dict[ 'name' ]
                rd_owner = repository_dependency_dict[ 'owner' ]
                rd_changeset_revision = repository_dependency_dict[ 'changeset_revision' ]
                if ( rd_name, rd_owner, rd_changeset_revision ) in exclude_repositories or \
                    ( rd_name, rd_owner, None ) in exclude_repositories:
                    log_msg = 'Revision %s of repository %s owned by %s is excluded from testing because ' % \
                        ( str( changeset_revision ), str( name ), str( owner ), str( reason ) )
                    log_msg += 'it requires revision %s of repository %s owned by %s (which is excluded from testing).' % \
                        ( rd_changeset_revision, rd_name, rd_owner )
                    log.debug( log_msg )
                    reason = 'This repository requires revision %s of repository %s owned by %s which is excluded from testing.' % \
                        ( rd_changeset_revision, rd_name, rd_owner )
                    return True, reason
                    break
    return False, None

def is_latest_downloadable_revision( url, repository_dict ):
    name = str( repository_dict[ 'name' ] )
    owner = str( repository_dict[ 'owner' ] )
    changeset_revision = str( repository_dict[ 'changeset_revision' ] )
    latest_revision = get_latest_downloadable_changeset_revision( url, name=name, owner=owner )
    return changeset_revision == str( latest_revision )

def json_from_url( url ):
    error_message = ''
    url_handle = urllib.urlopen( url )
    url_contents = url_handle.read()
    try:
        parsed_json = from_json_string( url_contents )
    except Exception, e:
        error_message = str( url_contents )
        log.exception( 'Error parsing JSON data in json_from_url(): %s.' % str( e ) )
        return None, error_message
    return parsed_json, error_message

def parse_exclude_list( xml_filename ):
    """Return a list of repositories to exclude from testing."""
    # This method expects an xml document that looks something like this:
    # <?xml version="1.0"?>
    # <blacklist>
    #    <repositories tool_shed="http://testtoolshed.g2.bx.psu.edu">
    #        <reason>
    #            <text>Some reason</text>
    #            <repository name="some_name" owner="some_owner" />
    #        </reason>
    #    </repositories>
    # </blacklist>
    # A list is returned with the following structure:
    # [{ 'reason': The default reason or the reason specified in this section,
    #    'repositories': [( name, owner, changeset_revision if changeset_revision else None ),
    #                     ( name, owner, changeset_revision if changeset_revision else None )]}]
    exclude_list = []
    exclude_tups = []
    xml_tree, error_message = parse_xml( xml_filename )
    if error_message:
        log.debug( 'The exclude file %s is invalid, so no repositories will be excluded from testing: %s' % \
            ( str( xml_filename ), str( error_message ) ) )
        return exclude_list
    tool_sheds = xml_tree.findall( 'repositories' )
    xml_element = []
    exclude_count = 0
    for tool_shed in tool_sheds:
        if galaxy_tool_shed_url != tool_shed.attrib[ 'tool_shed' ]:
            continue
        else:
            xml_element = tool_shed
    for reason_section in xml_element:
        reason_text = reason_section.find( 'text' )
        if reason_text:
            reason = str( reason_text.text )
        else:
            reason = 'No reason provided.'
        repositories = reason_section.findall( 'repository' )
        exclude_dict = dict( reason=reason, repositories=[] )
        for repository in repositories:
            repository_tuple = get_repository_tuple_from_elem( repository )
            if repository_tuple not in exclude_dict[ 'repositories' ]:
                exclude_tups.append( repository_tuple )
                exclude_count += 1
                exclude_dict[ 'repositories' ].append( repository_tuple )
        exclude_list.append( exclude_dict )
    if exclude_tups:
        log.debug( 'The exclude file %s defines the following %d repositories to be excluded from testing:' % \
            ( str( xml_filename ), exclude_count ) )
        for name, owner, changeset_revision in exclude_tups:
            if changeset_revision:
                log.debug( 'Revision %s of repository %s owned by %s.' % ( str( changeset_revision ), str( name ), str( owner ) ) )
            else:
                log.debug( 'All revisions of repository %s owned by %s.' % ( str( name ), str( owner ) ) )
    else:
        log.debug( 'The exclude file %s defines no repositories to be excluded from testing.' % str( xml_filename ) )
    return exclude_list

def populate_dependency_install_containers( app, repository, repository_identifier_dict, install_and_test_statistics_dict,
                                            tool_test_results_dict ):
    """
    Populate the installation containers (successful or errors) for the received repository's (which
    itself was successfully installed) immediate repository and tool dependencies.  The entire dependency
    tree is not handled here.
    """
    repository_name = str( repository.name )
    repository_owner = str( repository.owner )
    repository_changeset_revision = str( repository.changeset_revision )
    install_and_test_statistics_dict[ 'successful_repository_installations' ].append( repository_identifier_dict )
    tool_test_results_dict[ 'successful_installations' ][ 'current_repository' ].append( repository_identifier_dict )
    params = dict( test_install_error=False,
                   do_not_test=False )
    if repository.missing_repository_dependencies:
        log.debug( 'The following repository dependencies for revision %s of repository %s owned by %s have installation errors:' % \
            ( repository_changeset_revision, repository_name, repository_owner ) )
        params[ 'test_install_error' ] = True
        # Keep statistics for this repository's repository dependencies that resulted in installation errors.
        for missing_repository_dependency in repository.missing_repository_dependencies:
            tool_shed = str( missing_repository_dependency.tool_shed )
            name = str( missing_repository_dependency.name )
            owner = str( missing_repository_dependency.owner )
            changeset_revision = str( missing_repository_dependency.changeset_revision )
            error_message = unicodify( missing_repository_dependency.error_message )
            log.debug( 'Revision %s of repository %s owned by %s:\n%s' % ( changeset_revision, name, owner, error_message ) )
            missing_repository_dependency_info_dict = dict( tool_shed=tool_shed,
                                                            name=name,
                                                            owner=owner,
                                                            changeset_revision=changeset_revision,
                                                            error_message=error_message )
            install_and_test_statistics_dict[ 'repositories_with_installation_error' ].append( missing_repository_dependency_info_dict )
            tool_test_results_dict[ 'installation_errors' ][ 'repository_dependencies' ].append( missing_repository_dependency_info_dict )
    if repository.missing_tool_dependencies:
        log.debug( 'The following tool dependencies for revision %s of repository %s owned by %s have installation errors:' % \
            ( repository_changeset_revision, repository_name, repository_owner ) )
        params[ 'test_install_error' ] = True
        # Keep statistics for this repository's tool dependencies that resulted in installation errors.
        for missing_tool_dependency in repository.missing_tool_dependencies:
            name = str( missing_tool_dependency.name )
            type = str( missing_tool_dependency.type )
            version = str( missing_tool_dependency.version )
            error_message = unicodify( missing_tool_dependency.error_message )
            log.debug( 'Version %s of tool dependency %s %s:\n%s' % ( version, type, name, error_message ) )
            missing_tool_dependency_info_dict = dict( type=type,
                                                      name=name,
                                                      version=version,
                                                      error_message=error_message )
            install_and_test_statistics_dict[ 'tool_dependencies_with_installation_error' ].append( missing_tool_dependency_info_dict )
            tool_test_results_dict[ 'installation_errors' ][ 'tool_dependencies' ].append( missing_tool_dependency_info_dict )
    if repository.installed_repository_dependencies:
        log.debug( 'The following repository dependencies for revision %s of repository %s owned by %s are installed:' % \
            ( repository_changeset_revision, repository_name, repository_owner ) )
        # Keep statistics for this repository's tool dependencies that resulted in successful installations.
        for repository_dependency in repository.installed_repository_dependencies:
            tool_shed = str( repository_dependency.tool_shed )
            name = str( repository_dependency.name )
            owner = str( repository_dependency.owner )
            changeset_revision = str( repository_dependency.changeset_revision )
            log.debug( 'Revision %s of repository %s owned by %s.' % ( changeset_revision, name, owner ) )
            repository_dependency_info_dict = dict( tool_shed=tool_shed,
                                                    name=name,
                                                    owner=owner,
                                                    changeset_revision=changeset_revision )
            install_and_test_statistics_dict[ 'successful_repository_installations' ].append( repository_dependency_info_dict )
            tool_test_results_dict[ 'successful_installations' ][ 'repository_dependencies' ].append( repository_dependency_info_dict )
    if repository.installed_tool_dependencies:
        log.debug( 'The following tool dependencies for revision %s of repository %s owned by %s are installed:' % \
            ( repository_changeset_revision, repository_name, repository_owner ) )
        # Keep statistics for this repository's tool dependencies that resulted in successful installations.
        for tool_dependency in repository.installed_tool_dependencies:
            name = str( tool_dependency.name )
            type = str( tool_dependency.type )
            version = str( tool_dependency.version )
            installation_directory = tool_dependency.installation_directory( app )
            log.debug( 'Version %s of tool dependency %s %s is installed in: %s' % ( version, type, name, installation_directory ) )
            tool_dependency_info_dict = dict( type=type,
                                              name=name,
                                              version=version,
                                              installation_directory=installation_directory )
            install_and_test_statistics_dict[ 'successful_tool_dependency_installations' ].append( tool_dependency_info_dict )
            tool_test_results_dict[ 'successful_installations' ][ 'tool_dependencies' ].append( tool_dependency_info_dict )
    return params, install_and_test_statistics_dict, tool_test_results_dict

def populate_install_containers_for_repository_dependencies( app, repository, repository_metadata_id, install_and_test_statistics_dict,
                                                             can_update_tool_shed ):
    """
    The handle_repository_dependencies check box is always checked when a repository is installed, so the
    tool_test_results dictionary must be inspected for each dependency to make sure installation containers
    (success or errors) have been populated.  Since multiple repositories can depend on the same repository,
    some of the containers may have been populated during a previous installation.
    """
    # Get the list of dictionaries that define the received repository's repository dependencies
    # via the Tool Shed API.
    repository_name = str( repository.name )
    repository_owner = str( repository.owner )
    repository_changeset_revision = str( repository.changeset_revision )
    repository_dependencies_dicts, error_message = get_repository_dependencies_dicts( galaxy_tool_shed_url, repository_metadata_id )
    if error_message:
        log.debug( 'Cannot check or populate repository dependency install containers for version %s of repository %s owned by %s ' % \
            ( repository_changeset_revision, repository_name, repository_owner ) )
        log.debug( 'due to the following error getting repository_dependencies_dicts:\n%s' % str( error_message ) )
    else:
        for repository_dependencies_dict in repository_dependencies_dicts:
            if not isinstance( repository_dependencies_dict, dict ):
                log.debug( 'Skipping invalid repository_dependencies_dict: %s' % str( repository_dependencies_dict ) )
                continue
            name = repository_dependencies_dict.get( 'name', None )
            owner = repository_dependencies_dict.get( 'owner', None )
            changeset_revision = repository_dependencies_dict.get( 'changeset_revision', None )
            if name is None or owner is None or changeset_revision is None:
                log.debug( 'Skipping invalid repository_dependencies_dict due to missing name,owner or changeset_revision: %s' % \
                    str( repository_dependencies_dict ) )
                continue
            name = str( name )
            owner = str( owner )
            changeset_revision = str( changeset_revision )
            log.debug( 'Checking installation containers for revision %s of repository dependency %s owned by %s' % \
                ( changeset_revision, name, owner ) )
            required_repository_metadata_id = repository_dependencies_dict[ 'id' ]
            # Get the current list of tool_test_results dictionaries associated with the repository_metadata
            # record in the tool shed.
            tool_test_results_dicts, error_message = get_tool_test_results_dicts( galaxy_tool_shed_url,
                                                                                  required_repository_metadata_id )
            if error_message:
                log.debug( 'Cannot check install container for version %s of repository dependency %s owned by %s ' % \
                    ( changeset_revision, name, owner ) )
                log.debug( 'due to the following error getting tool_test_results:\n%s' % str( error_message ) )
            else:
                # Check the required repository's time_last_tested value to see if its tool_test_results column
                # has been updated within the past 12 hours.  The RepositoryMetadata class's to_dict() method
                # returns the value of time_last_tested in datetime.isoformat().
                twenty_hours_ago = ( datetime.utcnow() - timedelta( hours=20 ) ).isoformat()
                time_last_tested, error_message = get_time_last_tested( galaxy_tool_shed_url, repository_metadata_id )
                if time_last_tested is not None and time_last_tested < twenty_hours_ago:
                    log.debug( 'The install containers for version %s of repository dependency %s owned by %s have been ' % \
                        ( changeset_revision, name, owner ) )
                    log.debug( 'populated within the past 20 hours (likely in this test run), so skipping this check.' )
                    continue
                elif time_last_tested is None:
                    log.debug( 'The time_last_tested column value is None for version %s of repository dependency %s owned by %s.' % \
                        ( changeset_revision, name, owner ) )
                elif time_last_tested < twenty_hours_ago:
                    log.debug( 'Version %s of repository dependency %s owned by %s was last tested less than 20 hours ago.' % \
                        ( changeset_revision, name, owner ) )
                else:
                    log.debug( 'Version %s of repository dependency %s owned by %s was last tested more than 20 hours ago.' % \
                        ( changeset_revision, name, owner ) )
                # Inspect the tool_test_results_dict for the last test run to see if it has not yet been populated.
                if len( tool_test_results_dicts ) == 0:
                    tool_test_results_dict = {}
                else:
                    tool_test_results_dict = tool_test_results_dicts[ 0 ]
                    if len( tool_test_results_dict ) <= 1:
                        tool_test_results_dict = tool_test_results_dicts.pop( 0 )
                    elif len( tool_test_results_dict ) == 2 and \
                        'test_environment' in tool_test_results_dict and \
                        'missing_test_components' in tool_test_results_dict:
                        tool_test_results_dict = tool_test_results_dicts.pop( 0 )
                    else:
                        tool_test_results_dict = {}
                # Make sure all expected entries are available in the tool_test_results_dict.
                tool_test_results_dict = initialize_tool_tests_results_dict( app, tool_test_results_dict )
                # Get the installed repository record from the Galaxy database.
                cleaned_tool_shed_url = clean_tool_shed_url( galaxy_tool_shed_url )
                required_repository = \
                    suc.get_tool_shed_repository_by_shed_name_owner_changeset_revision( app,
                                                                                        cleaned_tool_shed_url,
                                                                                        name,
                                                                                        owner,
                                                                                        changeset_revision )
                if required_repository is not None:
                    repository_identifier_dict = dict( name=name, owner=owner, changeset_revision=changeset_revision )
                    if required_repository.is_installed:
                        # The required_repository was successfully installed, so populate the installation
                        # containers (success and error) for the repository's immediate dependencies.
                        params, install_and_test_statistics_dict, tool_test_results_dict = \
                            populate_dependency_install_containers( app,
                                                                    required_repository,
                                                                    repository_identifier_dict,
                                                                    install_and_test_statistics_dict,
                                                                    tool_test_results_dict )
                        response_dict = save_test_results_for_changeset_revision( galaxy_tool_shed_url,
                                                                                  tool_test_results_dicts,
                                                                                  tool_test_results_dict,
                                                                                  repository_dependencies_dict,
                                                                                  params,
                                                                                  can_update_tool_shed )
                        log.debug( 'Result of inserting tool_test_results for revision %s of repository %s owned by %s:\n%s' % \
                            ( changeset_revision, name, owner, str( response_dict ) ) )
                        log.debug('\n=============================================================\n' )
                    else:
                        # The required repository's installation failed.
                        tool_test_results_dict[ 'installation_errors' ][ 'current_repository' ] = str( required_repository.error_message )
                        params = dict( test_install_error=True,
                                       do_not_test=False )
                        response_dict = save_test_results_for_changeset_revision( galaxy_tool_shed_url,
                                                                                  tool_test_results_dicts,
                                                                                  tool_test_results_dict,
                                                                                  repository_dependencies_dict,
                                                                                  params,
                                                                                  can_update_tool_shed )
                        log.debug( 'Result of inserting tool_test_results for revision %s of repository %s owned by %s:\n%s' % \
                            ( changeset_revision, name, owner, str( response_dict ) ) )
                        log.debug('\n=============================================================\n' )
                else:
                    log.debug( 'Cannot retrieve revision %s of required repository %s owned by %s from the database ' % \
                        ( changeset_revision, name, owner ) )
                    log.debug( 'so tool_test_results cannot be saved at this time.' )
                    log.debug( 'The attributes used to retrieve the record are:' )
                    log.debug( 'tool_shed: %s name: %s owner: %s changeset_revision: %s' % \
                        ( cleaned_tool_shed_url, name, owner, changeset_revision ) )

def run_tests( test_config ):
    loader = nose.loader.TestLoader( config=test_config )
    test_config.plugins.addPlugin( ReportResults() )
    plug_loader = test_config.plugins.prepareTestLoader( loader )
    if plug_loader is not None:
        loader = plug_loader
    tests = loader.loadTestsFromNames( test_config.testNames )
    test_runner = nose.core.TextTestRunner( stream=test_config.stream,
                                            verbosity=test_config.verbosity,
                                            config=test_config )
    plug_runner = test_config.plugins.prepareTestRunner( test_runner )
    if plug_runner is not None:
        test_runner = plug_runner
    result = test_runner.run( tests )
    return result, test_config.plugins._plugins

def save_test_results_for_changeset_revision( url, tool_test_results_dicts, tool_test_results_dict, repository_dict,
                                              params, can_update_tool_shed ):
    """
    Update the repository metadata tool_test_results and appropriate flags using the Tool Shed API.  This method
    updates tool_test_results with the received tool_test_results_dict, sets the do_not_test and tools_functionally
    correct flags to the appropriate values and updates the time_last_tested field.
    """
    if can_update_tool_shed:
        metadata_revision_id = repository_dict.get( 'id', None )
        if metadata_revision_id is not None:
            name = str( repository_dict[ 'name' ] )
            owner = str( repository_dict[ 'owner' ] )
            changeset_revision = str( repository_dict[ 'changeset_revision' ] )
            log.debug('\n=============================================================\n' )
            log.debug( 'Inserting the following into tool_test_results for revision %s of repository %s owned by %s:\n%s' % \
                ( changeset_revision, name, owner, str( tool_test_results_dict ) ) )
            log.debug( 'Updating tool_test_results for repository_metadata id %s.' % str( metadata_revision_id ) )
            tool_test_results_dicts.insert( 0, tool_test_results_dict )
            params[ 'tool_test_results' ] = tool_test_results_dicts
            # Set the time_last_tested entry so that the repository_metadata.time_last_tested will be set in the tool shed.
            params[ 'time_last_tested' ] = 'This entry will result in this value being set via the Tool Shed API.'
            url = '%s' % ( suc.url_join( galaxy_tool_shed_url,'api', 'repository_revisions', str( metadata_revision_id ) ) )
            try:
                return update( tool_shed_api_key, url, params, return_formatted=False )
            except Exception, e:
                log.exception( 'Error updating tool_test_results for repository_metadata id %s:\n%s' % \
                    ( str( metadata_revision_id ), str( e ) ) )
                return {}
    else:
        return {}
