<tool id="pca_for_lda1" name="Calculate PC">
    <description>Principal Component Analysis</description>
    <command interpreter="sh">r_wrapper.sh $script_file</command>

    <inputs>
        <param format="tabular" name="input" type="data" label="Source file">
        </param>
    </inputs>

    <outputs>
        <data format="txt" name="output" />
    </outputs>

    <tests>
        <test>
            <param name="input" value="pca_and_lda_analy_for_lda_input.tabular"/>
            <output name="output" file="pca_for_lda_output.txt.re_match" compare="re_match"/>
        </test>
    </tests>

    <configfiles>
            <configfile name="script_file">

        rm(list = objects() )

        ############# FORMAT X DATA #########################
        format&lt;-function(data) {
            ind=NULL
            for(i in 1 : ncol(data)){
                if (is.na(data[nrow(data),i])) {
                    ind&lt;-c(ind,i)
                }
            }
            #print(is.null(ind))
            if (!is.null(ind)) {
                data&lt;-data[,-c(ind)]
            }

            data
        }

        ########GET RESPONSES ###############################
        get_resp&lt;- function(data) {
            resp1&lt;-as.vector(data[,ncol(data)])
                resp=numeric(length(resp1))
            for (i in 1:length(resp1)) {
                if (resp1[i]=="Control ") {
                    resp[i] = 0
                }
                if (resp1[i]=="XLMR ") {
                    resp[i] = 1
                }
            }
                return(resp)
        }

        ######## CHARS TO NUMBERS ###########################
        f_to_numbers&lt;- function(F) { 
            ind&lt;-NULL
            G&lt;-matrix(0,nrow(F), ncol(F))
            for (i in 1:nrow(F)) {
                for (j in 1:ncol(F)) {
                    G[i,j]&lt;-as.integer(F[i,j])
                }
            }
            return(G)
        }

        ###################NORMALIZING#########################
        norm &lt;- function(M, a=NULL, b=NULL) {
            C&lt;-NULL
            ind&lt;-NULL

            for (i in 1: ncol(M)) {
                if (sd(M[,i])!=0) {
                    M[,i]&lt;-(M[,i]-mean(M[,i]))/sd(M[,i])
                }
                #   else {print(mean(M[,i]))}   
            }
            return(M)
        }

        ##### LDA DIRECTIONS #################################
        lda_dec &lt;- function(data, k){
            priors=numeric(k)
            grandmean&lt;-numeric(ncol(data)-1)
            means=matrix(0,k,ncol(data)-1)
            B = matrix(0, ncol(data)-1, ncol(data)-1)
            N=nrow(data)
            for (i in 1:k){
                priors[i]=sum(data[,1]==i)/N
                grp=subset(data,data\$group==i)
                means[i,]=mean(grp[,2:ncol(data)])
                #print(means[i,])
                #print(priors[i])
                #print(priors[i]*means[i,])
                grandmean = priors[i]*means[i,] + grandmean           
            }

            for (i in 1:k) {
                B= B + priors[i]*((means[i,]-grandmean)%*%t(means[i,]-grandmean))
            }
    
            W = var(data[,2:ncol(data)])
            svdW = svd(W)
            inv_sqrtW =solve(svdW\$v %*% diag(sqrt(svdW\$d)) %*% t(svdW\$v))
            B_star= t(inv_sqrtW)%*%B%*%inv_sqrtW
            B_star_decomp = svd(B_star)
            directions  = inv_sqrtW%*%B_star_decomp\$v
            return( list(directions, B_star_decomp\$d) )                          
        }

        ################ NAIVE BAYES FOR 1D SIR OR LDA ##############
        naive_bayes_classifier &lt;- function(resp, tr_data, test_data, k=2, tau) {
            tr_data=data.frame(resp=resp, dir=tr_data)
            means=numeric(k)
            #print(k)
            cl=numeric(k)
            predclass=numeric(length(test_data))
            for (i in 1:k) {
                grp = subset(tr_data, resp==i)
                means[i] = mean(grp\$dir)
            #print(i, means[i])  
            }
            cutoff = tau*means[1]+(1-tau)*means[2] 
            #print(tau)
            #print(means)
            #print(cutoff)
            if (cutoff&gt;means[1]) {
               cl[1]=1 
               cl[2]=2
            }
            else {
               cl[1]=2 
               cl[2]=1
            }

            for (i in 1:length(test_data)) {

                if (test_data[i] &lt;= cutoff) {
                    predclass[i] = cl[1]
            }
                else {
                    predclass[i] = cl[2] 
            }  
                }
            #print(means)
            #print(mean(means))
            #X11()
            #plot(test_data,pch=predclass, col=resp) 
            predclass
        }

        ################# EXTENDED ERROR RATES #################
        ext_error_rate &lt;- function(predclass, actualclass,msg=c("you forgot the message"), pr=1) {
                 er=sum(predclass != actualclass)/length(predclass)

                 matr&lt;-data.frame(predclass=predclass,actualclass=actualclass)
                 escapes = subset(matr, actualclass==1)
                 subjects = subset(matr, actualclass==2)      
                 er_esc=sum(escapes\$predclass != escapes\$actualclass)/length(escapes\$predclass) 
                 er_subj=sum(subjects\$predclass != subjects\$actualclass)/length(subjects\$predclass)   

                 if (pr==1) {
        #             print(paste(c(msg, 'overall : ', (1-er)*100, "%."),collapse=" "))
        #             print(paste(c(msg, 'within escapes : ', (1-er_esc)*100, "%."),collapse=" "))
        #             print(paste(c(msg, 'within subjects: ', (1-er_subj)*100, "%."),collapse=" ")) 
            }
            return(c((1-er)*100, (1-er_esc)*100, (1-er_subj)*100))                                                                                    
        }

        ## Main Function ##

        files&lt;-matrix("${input}", 1,1, byrow=T)

        tau&lt;-seq(0,1, by=0.005)
        #tau&lt;-seq(0,1, by=0.1)
        for_curve=matrix(-10, 3,length(tau))

        ##############################################################

        test_data_whole_X &lt;-read.delim(files[1,1], row.names=1)

        #### FORMAT TRAINING DATA ####################################
        # get only necessary columns 

        test_data_whole_X&lt;-format(test_data_whole_X)
        oligo_labels&lt;-test_data_whole_X[1:(nrow(test_data_whole_X)-1),ncol(test_data_whole_X)]
        test_data_whole_X&lt;-test_data_whole_X[,1:(ncol(test_data_whole_X)-1)]

        X_names&lt;-colnames(test_data_whole_X)[1:ncol(test_data_whole_X)]
        test_data_whole_X&lt;-t(test_data_whole_X)
        resp&lt;-get_resp(test_data_whole_X) 
        ldaqda_resp = resp + 1
        a&lt;-sum(resp)        # Number of Subject
        b&lt;-length(resp) - a # Number of Escape   
        ## FREQUENCIES #################################################
        F&lt;-test_data_whole_X[,1:(ncol(test_data_whole_X)-1)]
        F&lt;-f_to_numbers(F)
        FN&lt;-norm(F, a, b)
        ss&lt;-svd(FN)
        eigvar&lt;-NULL
        eig&lt;-ss\$d^2

        print_out &lt;- c(rep('NA', length(ss\$d)))
        for ( i in 1:length(ss\$d)) {
            eigvar[i]&lt;-sum(eig[1:i])/sum(eig)
        #   print(paste(c("Variance explained : ", eigvar[i]*100, "  %"), collapse=""))
            print_out[i] &lt;- c(eigvar[i]*100)
        }

        #My_Names &lt;- c("order of principal components", "accumulated variance explained", "")
        #names(print_out)&lt;-My_Names

        write.table(print_out, file = "${output}", col.names = FALSE, row.names = FALSE)

        </configfile>
    </configfiles>

    <help>

.. class:: infomark

**What it does**

This tool consists of the first module to perform the Principal Component Analysis as described in Carrel et al., 2006 (PMID: 17009873)

*Carrel L, Park C, Tyekucheva S, Dunn J, Chiaromonte F, et al. (2006) Genomic Environment Predicts Expression Patterns on the Human     Inactive X Chromosome. PLoS Genet 2(9): e151. doi:10.1371/journal.pgen.0020151*

-----

**Example**

- Input file

.. image:: ../static/images/tools/lda/LDA_Input.png

- Output file

    The values indicate "accumulated variance explained (%)" and were sorted by the order of principal components (i.e., 1st, 2nd, 3rd, 4th...).


</help>

</tool>
